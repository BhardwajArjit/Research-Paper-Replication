{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNArl2aiuvZ9bbbFnWt41km",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhardwajArjit/Research-Paper-Replication/blob/main/ResNet%2BCBAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook implements ResNet with CBAM.\n",
        "\n",
        "ResNet (Residual Network) is a deep neural network architecture that uses skip connections to facilitate training of very deep convolutional neural networks.\n",
        "\n",
        "CBAM (Convolutional Block Attention Module) aims to enhance the feature representation of convolutional neural networks by incorporating channel-wise and spatial-wise attention mechanisms."
      ],
      "metadata": {
        "id": "e3AF4bmiK9sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Get setup"
      ],
      "metadata": {
        "id": "bh2584jzNnCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torchsummary import summary\n",
        "import torch.utils.model_zoo as model_zoo"
      ],
      "metadata": {
        "id": "3K6oKU7BJSXM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get ResNet models"
      ],
      "metadata": {
        "id": "SpJr6qtQNq3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}"
      ],
      "metadata": {
        "id": "BgbKDfz8Jndy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ResNet + CBAM"
      ],
      "metadata": {
        "id": "iOSHLkvmN9Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "  \"\"\"\n",
        "  3x3 convolution with padding.\n",
        "\n",
        "  Parameters:\n",
        "  - in_planes (int): Number of input channels.\n",
        "  - out_planes (int): Number of output channels.\n",
        "  - stride (int, optional): Stride for the convolution operation. Default is 1.\n",
        "\n",
        "  Returns:\n",
        "  - nn.Conv2d: 3x3 convolutional layer with specified parameters.\n",
        "  \"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                    padding=1, bias=False)"
      ],
      "metadata": {
        "id": "7A3-X7VdJr3N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "  \"\"\"\n",
        "  Channel Attention Module.\n",
        "\n",
        "  Parameters:\n",
        "  - in_planes (int): Number of input channels.\n",
        "  - ratio (int, optional): Reduction ratio for the intermediate channels. Default is 16.\n",
        "  \"\"\"\n",
        "  def __init__(self, in_planes, ratio=16):\n",
        "    super(ChannelAttention, self).__init__()\n",
        "    # Adaptive average pooling layer to capture global average information\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "    # Adaptive max pooling layer to capture global max information\n",
        "    self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "    # First convolutional layer for dimension reduction\n",
        "    self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
        "    # ReLU activation function\n",
        "    self.relu1 = nn.ReLU()\n",
        "    # Second convolutional layer for dimension restoration\n",
        "    self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
        "    # Sigmoid activation function to produce attention weights between 0 and 1\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "    max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "    # Element-wise addition of the average and max pooling results\n",
        "    out = avg_out + max_out\n",
        "    # Apply the sigmoid activation to produce attention weights\n",
        "    return self.sigmoid(out)"
      ],
      "metadata": {
        "id": "O_2OaLF3Jub0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpatialAttention(nn.Module):\n",
        "  \"\"\"\n",
        "  Spatial Attention Module.\n",
        "\n",
        "  Parameters:\n",
        "  - kernel_size (int, optional): Size of the convolutional kernel. Must be 3 or 7. Default is 7.\n",
        "  \"\"\"\n",
        "  def __init__(self, kernel_size=7):\n",
        "    super(SpatialAttention, self).__init__()\n",
        "\n",
        "    assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "    padding = 3 if kernel_size == 7 else 1\n",
        "    # Convolutional layer for generating spatial attention map\n",
        "    self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "    # Sigmoid activation function to produce attention weights between 0 and 1\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Compute the mean along the channel dimension\n",
        "    avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "    # Compute the maximum along the channel dimension\n",
        "    max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "    x = torch.cat([avg_out, max_out], dim=1)\n",
        "    # Pass the concatenated features through the convolutional layer to compute the spatial attention map\n",
        "    x = self.conv1(x)\n",
        "    # Apply sigmoid activation to produce attention weights\n",
        "    return self.sigmoid(x)"
      ],
      "metadata": {
        "id": "yuqrsfQaJxIL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  \"\"\"\n",
        "  Basic Residual Block.\n",
        "\n",
        "  Parameters:\n",
        "  - inplanes (int): Number of input channels.\n",
        "  - planes (int): Number of output channels.\n",
        "  - stride (int, optional): Stride for the convolution operation. Default is 1.\n",
        "  - downsample (nn.Module, optional): Downsample layer to match dimensions. Default is None.\n",
        "  \"\"\"\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "    super(BasicBlock, self).__init__()\n",
        "\n",
        "    # First convolutional layer with batch normalization and ReLU activation\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    # Second convolutional layer with batch normalization\n",
        "    self.conv2 = conv3x3(planes, planes)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    # Channel attention and spatial attention modules\n",
        "    self.ca = ChannelAttention(planes)\n",
        "    self.sa = SpatialAttention()\n",
        "\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of the BasicBlock.\n",
        "\n",
        "    Parameters:\n",
        "    - x (torch.Tensor): Input tensor.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: Output tensor after applying the BasicBlock.\n",
        "    \"\"\"\n",
        "    # Save the input tensor for the residual connection\n",
        "    residual = x\n",
        "\n",
        "    # First convolutional block\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    # Second convolutional block\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    # Apply channel attention and spatial attention\n",
        "    out = self.ca(out) * out\n",
        "    out = self.sa(out) * out\n",
        "\n",
        "    # If downsample is provided, apply it to the residual\n",
        "    if self.downsample is not None:\n",
        "        residual = self.downsample(x)\n",
        "\n",
        "    # Add the residual connection\n",
        "    out += residual\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "_WLhy8K4J3mt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "  \"\"\"\n",
        "  Bottleneck Residual Block.\n",
        "\n",
        "  Parameters:\n",
        "  - inplanes (int): Number of input channels.\n",
        "  - planes (int): Number of output channels.\n",
        "  - stride (int, optional): Stride for the convolution operation. Default is 1.\n",
        "  - downsample (nn.Module, optional): Downsample layer to match dimensions. Default is None.\n",
        "  \"\"\"\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "    super(Bottleneck, self).__init__()\n",
        "\n",
        "    # First 1x1 convolutional layer\n",
        "    self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    # Second 3x3 convolutional layer with stride\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                            padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    # Third 1x1 convolutional layer with increased output channels\n",
        "    self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "\n",
        "    # ReLU activation function\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    # Channel attention and spatial attention modules\n",
        "    self.ca = ChannelAttention(planes * 4)\n",
        "    self.sa = SpatialAttention()\n",
        "\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of the Bottleneck.\n",
        "\n",
        "    Parameters:\n",
        "    - x (torch.Tensor): Input tensor.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: Output tensor after applying the Bottleneck.\n",
        "    \"\"\"\n",
        "    # Save the input tensor for the residual connection\n",
        "    residual = x\n",
        "\n",
        "    # First 1x1 convolutional block\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    # Second 1x1 convolutional block\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    # Third 1x1 convolutional block\n",
        "    out = self.conv3(out)\n",
        "    out = self.bn3(out)\n",
        "\n",
        "    # Apply channel attention and spatial attention\n",
        "    out = self.ca(out) * out\n",
        "    out = self.sa(out) * out\n",
        "\n",
        "    # If downsample is provided, apply it to the residual\n",
        "    if self.downsample is not None:\n",
        "        residual = self.downsample(x)\n",
        "\n",
        "    # Add the residual connection\n",
        "    out += residual\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "kQRtrEuBJ8nI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  \"\"\"\n",
        "  ResNet model.\n",
        "\n",
        "  Parameters:\n",
        "  - block (nn.Module): Residual block class (e.g., BasicBlock or Bottleneck).\n",
        "  - layers (list): List of integers indicating the number of blocks in each layer.\n",
        "  - num_classes (int, optional): Number of output classes. Default is 1000.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, block, layers, num_classes=1000):\n",
        "    self.inplanes = 64\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    # Initial convolutional layer\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                            bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    # Residual layers\n",
        "    self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "    self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "    # Global average pooling and fully connected layer\n",
        "    self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    # Initialization of weights and batch normalization parameters\n",
        "    for m in self.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            m.weight.data.fill_(1)\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "  def _make_layer(self, block, planes, blocks, stride=1):\n",
        "    \"\"\"\n",
        "    Helper function to create a residual layer.\n",
        "\n",
        "    Parameters:\n",
        "    - block (nn.Module): Residual block class (e.g., BasicBlock or Bottleneck).\n",
        "    - planes (int): Number of output channels in each block.\n",
        "    - blocks (int): Number of blocks in the layer.\n",
        "    - stride (int, optional): Stride for the first block. Default is 1.\n",
        "\n",
        "    Returns:\n",
        "    - nn.Sequential: Residual layer.\n",
        "    \"\"\"\n",
        "    downsample = None\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "        downsample = nn.Sequential(\n",
        "            nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                      kernel_size=1, stride=stride, bias=False),\n",
        "            nn.BatchNorm2d(planes * block.expansion),\n",
        "        )\n",
        "\n",
        "    layers = []\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "    self.inplanes = planes * block.expansion\n",
        "    for i in range(1, blocks):\n",
        "        layers.append(block(self.inplanes, planes))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass of the ResNet model.\n",
        "\n",
        "    Parameters:\n",
        "    - x (torch.Tensor): Input tensor.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: Output tensor.\n",
        "    \"\"\"\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "3tQ2OIpsKClm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18_cbam(pretrained=False, **kwargs):\n",
        "  \"\"\"\n",
        "  Constructs a ResNet-18 model.\n",
        "\n",
        "  Args:\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "  \"\"\"\n",
        "  model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "  if pretrained:\n",
        "      pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])\n",
        "      now_state_dict        = model.state_dict()\n",
        "      now_state_dict.update(pretrained_state_dict)\n",
        "      model.load_state_dict(now_state_dict)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Eoa-t3b2KJTT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet34_cbam(pretrained=False, **kwargs):\n",
        "  \"\"\"\n",
        "  Constructs a ResNet-34 model.\n",
        "\n",
        "  Args:\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "  \"\"\"\n",
        "  model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "  if pretrained:\n",
        "      pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])\n",
        "      now_state_dict        = model.state_dict()\n",
        "      now_state_dict.update(pretrained_state_dict)\n",
        "      model.load_state_dict(now_state_dict)\n",
        "  return model"
      ],
      "metadata": {
        "id": "QlXDyOUOKLZ5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet50_cbam(pretrained=False, **kwargs):\n",
        "  \"\"\"\n",
        "  Constructs a ResNet-50 model.\n",
        "\n",
        "  Args:\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "  \"\"\"\n",
        "  model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "  if pretrained:\n",
        "      pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])\n",
        "      now_state_dict        = model.state_dict()\n",
        "      now_state_dict.update(pretrained_state_dict)\n",
        "      model.load_state_dict(now_state_dict)\n",
        "  return model"
      ],
      "metadata": {
        "id": "zbPmsE3GKOrz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet101_cbam(pretrained=False, **kwargs):\n",
        "  \"\"\"\n",
        "  Constructs a ResNet-101 model.\n",
        "\n",
        "  Args:\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "  \"\"\"\n",
        "  model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "  if pretrained:\n",
        "      pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])\n",
        "      now_state_dict        = model.state_dict()\n",
        "      now_state_dict.update(pretrained_state_dict)\n",
        "      model.load_state_dict(now_state_dict)\n",
        "  return model"
      ],
      "metadata": {
        "id": "z1ODyvWUKQyF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jxfpZDtBJIMN"
      },
      "outputs": [],
      "source": [
        "def resnet152_cbam(pretrained=False, **kwargs):\n",
        "  \"\"\"\n",
        "  Constructs a ResNet-152 model.\n",
        "\n",
        "  Args:\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "  \"\"\"\n",
        "  model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "  if pretrained:\n",
        "      pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])\n",
        "      now_state_dict        = model.state_dict()\n",
        "      now_state_dict.update(pretrained_state_dict)\n",
        "      model.load_state_dict(now_state_dict)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = resnet18_cbam()"
      ],
      "metadata": {
        "id": "g70kiiSvQA0e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(resnet18, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tKoY81FQHTw",
        "outputId": "9be013eb-5221-459f-d909-74b8d9e64f4d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "AdaptiveAvgPool2d-10             [-1, 64, 1, 1]               0\n",
            "           Conv2d-11              [-1, 4, 1, 1]             256\n",
            "             ReLU-12              [-1, 4, 1, 1]               0\n",
            "           Conv2d-13             [-1, 64, 1, 1]             256\n",
            "AdaptiveMaxPool2d-14             [-1, 64, 1, 1]               0\n",
            "           Conv2d-15              [-1, 4, 1, 1]             256\n",
            "             ReLU-16              [-1, 4, 1, 1]               0\n",
            "           Conv2d-17             [-1, 64, 1, 1]             256\n",
            "          Sigmoid-18             [-1, 64, 1, 1]               0\n",
            " ChannelAttention-19             [-1, 64, 1, 1]               0\n",
            "           Conv2d-20            [-1, 1, 56, 56]              98\n",
            "          Sigmoid-21            [-1, 1, 56, 56]               0\n",
            " SpatialAttention-22            [-1, 1, 56, 56]               0\n",
            "             ReLU-23           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-24           [-1, 64, 56, 56]               0\n",
            "           Conv2d-25           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-26           [-1, 64, 56, 56]             128\n",
            "             ReLU-27           [-1, 64, 56, 56]               0\n",
            "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
            "AdaptiveAvgPool2d-30             [-1, 64, 1, 1]               0\n",
            "           Conv2d-31              [-1, 4, 1, 1]             256\n",
            "             ReLU-32              [-1, 4, 1, 1]               0\n",
            "           Conv2d-33             [-1, 64, 1, 1]             256\n",
            "AdaptiveMaxPool2d-34             [-1, 64, 1, 1]               0\n",
            "           Conv2d-35              [-1, 4, 1, 1]             256\n",
            "             ReLU-36              [-1, 4, 1, 1]               0\n",
            "           Conv2d-37             [-1, 64, 1, 1]             256\n",
            "          Sigmoid-38             [-1, 64, 1, 1]               0\n",
            " ChannelAttention-39             [-1, 64, 1, 1]               0\n",
            "           Conv2d-40            [-1, 1, 56, 56]              98\n",
            "          Sigmoid-41            [-1, 1, 56, 56]               0\n",
            " SpatialAttention-42            [-1, 1, 56, 56]               0\n",
            "             ReLU-43           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-44           [-1, 64, 56, 56]               0\n",
            "           Conv2d-45          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
            "             ReLU-47          [-1, 128, 28, 28]               0\n",
            "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
            "AdaptiveAvgPool2d-50            [-1, 128, 1, 1]               0\n",
            "           Conv2d-51              [-1, 8, 1, 1]           1,024\n",
            "             ReLU-52              [-1, 8, 1, 1]               0\n",
            "           Conv2d-53            [-1, 128, 1, 1]           1,024\n",
            "AdaptiveMaxPool2d-54            [-1, 128, 1, 1]               0\n",
            "           Conv2d-55              [-1, 8, 1, 1]           1,024\n",
            "             ReLU-56              [-1, 8, 1, 1]               0\n",
            "           Conv2d-57            [-1, 128, 1, 1]           1,024\n",
            "          Sigmoid-58            [-1, 128, 1, 1]               0\n",
            " ChannelAttention-59            [-1, 128, 1, 1]               0\n",
            "           Conv2d-60            [-1, 1, 28, 28]              98\n",
            "          Sigmoid-61            [-1, 1, 28, 28]               0\n",
            " SpatialAttention-62            [-1, 1, 28, 28]               0\n",
            "           Conv2d-63          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-64          [-1, 128, 28, 28]             256\n",
            "             ReLU-65          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-66          [-1, 128, 28, 28]               0\n",
            "           Conv2d-67          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
            "             ReLU-69          [-1, 128, 28, 28]               0\n",
            "           Conv2d-70          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-71          [-1, 128, 28, 28]             256\n",
            "AdaptiveAvgPool2d-72            [-1, 128, 1, 1]               0\n",
            "           Conv2d-73              [-1, 8, 1, 1]           1,024\n",
            "             ReLU-74              [-1, 8, 1, 1]               0\n",
            "           Conv2d-75            [-1, 128, 1, 1]           1,024\n",
            "AdaptiveMaxPool2d-76            [-1, 128, 1, 1]               0\n",
            "           Conv2d-77              [-1, 8, 1, 1]           1,024\n",
            "             ReLU-78              [-1, 8, 1, 1]               0\n",
            "           Conv2d-79            [-1, 128, 1, 1]           1,024\n",
            "          Sigmoid-80            [-1, 128, 1, 1]               0\n",
            " ChannelAttention-81            [-1, 128, 1, 1]               0\n",
            "           Conv2d-82            [-1, 1, 28, 28]              98\n",
            "          Sigmoid-83            [-1, 1, 28, 28]               0\n",
            " SpatialAttention-84            [-1, 1, 28, 28]               0\n",
            "             ReLU-85          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-86          [-1, 128, 28, 28]               0\n",
            "           Conv2d-87          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-88          [-1, 256, 14, 14]             512\n",
            "             ReLU-89          [-1, 256, 14, 14]               0\n",
            "           Conv2d-90          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-91          [-1, 256, 14, 14]             512\n",
            "AdaptiveAvgPool2d-92            [-1, 256, 1, 1]               0\n",
            "           Conv2d-93             [-1, 16, 1, 1]           4,096\n",
            "             ReLU-94             [-1, 16, 1, 1]               0\n",
            "           Conv2d-95            [-1, 256, 1, 1]           4,096\n",
            "AdaptiveMaxPool2d-96            [-1, 256, 1, 1]               0\n",
            "           Conv2d-97             [-1, 16, 1, 1]           4,096\n",
            "             ReLU-98             [-1, 16, 1, 1]               0\n",
            "           Conv2d-99            [-1, 256, 1, 1]           4,096\n",
            "         Sigmoid-100            [-1, 256, 1, 1]               0\n",
            "ChannelAttention-101            [-1, 256, 1, 1]               0\n",
            "          Conv2d-102            [-1, 1, 14, 14]              98\n",
            "         Sigmoid-103            [-1, 1, 14, 14]               0\n",
            "SpatialAttention-104            [-1, 1, 14, 14]               0\n",
            "          Conv2d-105          [-1, 256, 14, 14]          32,768\n",
            "     BatchNorm2d-106          [-1, 256, 14, 14]             512\n",
            "            ReLU-107          [-1, 256, 14, 14]               0\n",
            "      BasicBlock-108          [-1, 256, 14, 14]               0\n",
            "          Conv2d-109          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-110          [-1, 256, 14, 14]             512\n",
            "            ReLU-111          [-1, 256, 14, 14]               0\n",
            "          Conv2d-112          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-113          [-1, 256, 14, 14]             512\n",
            "AdaptiveAvgPool2d-114            [-1, 256, 1, 1]               0\n",
            "          Conv2d-115             [-1, 16, 1, 1]           4,096\n",
            "            ReLU-116             [-1, 16, 1, 1]               0\n",
            "          Conv2d-117            [-1, 256, 1, 1]           4,096\n",
            "AdaptiveMaxPool2d-118            [-1, 256, 1, 1]               0\n",
            "          Conv2d-119             [-1, 16, 1, 1]           4,096\n",
            "            ReLU-120             [-1, 16, 1, 1]               0\n",
            "          Conv2d-121            [-1, 256, 1, 1]           4,096\n",
            "         Sigmoid-122            [-1, 256, 1, 1]               0\n",
            "ChannelAttention-123            [-1, 256, 1, 1]               0\n",
            "          Conv2d-124            [-1, 1, 14, 14]              98\n",
            "         Sigmoid-125            [-1, 1, 14, 14]               0\n",
            "SpatialAttention-126            [-1, 1, 14, 14]               0\n",
            "            ReLU-127          [-1, 256, 14, 14]               0\n",
            "      BasicBlock-128          [-1, 256, 14, 14]               0\n",
            "          Conv2d-129            [-1, 512, 7, 7]       1,179,648\n",
            "     BatchNorm2d-130            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-131            [-1, 512, 7, 7]               0\n",
            "          Conv2d-132            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-133            [-1, 512, 7, 7]           1,024\n",
            "AdaptiveAvgPool2d-134            [-1, 512, 1, 1]               0\n",
            "          Conv2d-135             [-1, 32, 1, 1]          16,384\n",
            "            ReLU-136             [-1, 32, 1, 1]               0\n",
            "          Conv2d-137            [-1, 512, 1, 1]          16,384\n",
            "AdaptiveMaxPool2d-138            [-1, 512, 1, 1]               0\n",
            "          Conv2d-139             [-1, 32, 1, 1]          16,384\n",
            "            ReLU-140             [-1, 32, 1, 1]               0\n",
            "          Conv2d-141            [-1, 512, 1, 1]          16,384\n",
            "         Sigmoid-142            [-1, 512, 1, 1]               0\n",
            "ChannelAttention-143            [-1, 512, 1, 1]               0\n",
            "          Conv2d-144              [-1, 1, 7, 7]              98\n",
            "         Sigmoid-145              [-1, 1, 7, 7]               0\n",
            "SpatialAttention-146              [-1, 1, 7, 7]               0\n",
            "          Conv2d-147            [-1, 512, 7, 7]         131,072\n",
            "     BatchNorm2d-148            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-149            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-150            [-1, 512, 7, 7]               0\n",
            "          Conv2d-151            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-152            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-153            [-1, 512, 7, 7]               0\n",
            "          Conv2d-154            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-155            [-1, 512, 7, 7]           1,024\n",
            "AdaptiveAvgPool2d-156            [-1, 512, 1, 1]               0\n",
            "          Conv2d-157             [-1, 32, 1, 1]          16,384\n",
            "            ReLU-158             [-1, 32, 1, 1]               0\n",
            "          Conv2d-159            [-1, 512, 1, 1]          16,384\n",
            "AdaptiveMaxPool2d-160            [-1, 512, 1, 1]               0\n",
            "          Conv2d-161             [-1, 32, 1, 1]          16,384\n",
            "            ReLU-162             [-1, 32, 1, 1]               0\n",
            "          Conv2d-163            [-1, 512, 1, 1]          16,384\n",
            "         Sigmoid-164            [-1, 512, 1, 1]               0\n",
            "ChannelAttention-165            [-1, 512, 1, 1]               0\n",
            "          Conv2d-166              [-1, 1, 7, 7]              98\n",
            "         Sigmoid-167              [-1, 1, 7, 7]               0\n",
            "SpatialAttention-168              [-1, 1, 7, 7]               0\n",
            "            ReLU-169            [-1, 512, 7, 7]               0\n",
            "      BasicBlock-170            [-1, 512, 7, 7]               0\n",
            "       AvgPool2d-171            [-1, 512, 1, 1]               0\n",
            "          Linear-172                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,864,376\n",
            "Trainable params: 11,864,376\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 63.07\n",
            "Params size (MB): 45.26\n",
            "Estimated Total Size (MB): 108.91\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8AREmvsQLtE"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}