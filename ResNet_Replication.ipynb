{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSSLdJ+wk4bK5TiWvMxnv4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhardwajArjit/Research-Paper-Replication/blob/main/ResNet_Replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook replicates the research paper titled \"**Deep Residual Learning for Image Recognition**\" with PyTorch.\n",
        "\n",
        "The link to the paper: https://arxiv.org/abs/1512.03385\n",
        "\n",
        "ResNet (Residual Network) is a deep neural network architecture that uses skip connections to facilitate training of very deep convolutional neural networks."
      ],
      "metadata": {
        "id": "9Rlre1T3Sv50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Get setup"
      ],
      "metadata": {
        "id": "R8g_uICpesBS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_1P56cgfXfJX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "zU1QR88PfRFg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOOg10nwfUAG",
        "outputId": "e9d833db-59e8-4fc6-ecd3-461467550168"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_PvandVffea",
        "outputId": "fd93a3bd-065f-488c-b533-54a795906327"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov  9 14:31:39 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)"
      ],
      "metadata": {
        "id": "Jwd4oSfZga83"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, option='A'):\n",
        "        super(BasicConvBlock, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv1', nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)),\n",
        "            ('bn1', nn.BatchNorm2d(out_channels)),\n",
        "            ('act1', nn.ReLU()),\n",
        "            ('conv2', nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "            ('bn2', nn.BatchNorm2d(out_channels))\n",
        "        ]))\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            if option == 'A':\n",
        "                # Use identity shortcuts with zero padding to increase channel dimension.\n",
        "                pad_to_add = out_channels//4\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                            F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad_to_add, pad_to_add, 0,0)))\n",
        "            if option == 'B':\n",
        "                self.shortcut = nn.Sequential(OrderedDict([\n",
        "                    ('s_conv1', nn.Conv2d(in_channels, 2*out_channels, kernel_size=1, stride=stride, padding=0, bias=False)),\n",
        "                    ('s_bn1', nn.BatchNorm2d(2*out_channels))\n",
        "                ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        # sum it up with shortcut layer\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Rb6cvMN0fum1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block_type, num_blocks):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.in_channels = 16\n",
        "\n",
        "        self.conv0 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn0 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.block1 = self.__build_layer(block_type, 16, num_blocks[0], starting_stride=1)\n",
        "\n",
        "        self.block2 = self.__build_layer(block_type, 32, num_blocks[1], starting_stride=2)\n",
        "\n",
        "        self.block3 = self.__build_layer(block_type, 64, num_blocks[2], starting_stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.linear = nn.Linear(64, 10)\n",
        "\n",
        "    def __build_layer(self, block_type, out_channels, num_blocks, starting_stride):\n",
        "        strides_list_for_current_block = [starting_stride] + [1]*(num_blocks-1)\n",
        "\n",
        "        # print('strides_list_for_current_block ', strides_list_for_current_block)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides_list_for_current_block:\n",
        "            layers.append(block_type(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn0(self.conv0(x)))\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "-xibFTiLgc9m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet56():\n",
        "    return ResNet(block_type=BasicConvBlock, num_blocks=[9,9,9])"
      ],
      "metadata": {
        "id": "5EuvojjvgzFI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet56()\n",
        "model.to(device)\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNBQ3ITwg_Ij",
        "outputId": "61834b68-70c8-48c8-bd63-c47a8a5ebd98"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
            "              ReLU-5           [-1, 16, 32, 32]               0\n",
            "            Conv2d-6           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
            "    BasicConvBlock-8           [-1, 16, 32, 32]               0\n",
            "            Conv2d-9           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-10           [-1, 16, 32, 32]              32\n",
            "             ReLU-11           [-1, 16, 32, 32]               0\n",
            "           Conv2d-12           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-13           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-14           [-1, 16, 32, 32]               0\n",
            "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
            "             ReLU-17           [-1, 16, 32, 32]               0\n",
            "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-20           [-1, 16, 32, 32]               0\n",
            "           Conv2d-21           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
            "             ReLU-23           [-1, 16, 32, 32]               0\n",
            "           Conv2d-24           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-25           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-26           [-1, 16, 32, 32]               0\n",
            "           Conv2d-27           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-28           [-1, 16, 32, 32]              32\n",
            "             ReLU-29           [-1, 16, 32, 32]               0\n",
            "           Conv2d-30           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-31           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-32           [-1, 16, 32, 32]               0\n",
            "           Conv2d-33           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-34           [-1, 16, 32, 32]              32\n",
            "             ReLU-35           [-1, 16, 32, 32]               0\n",
            "           Conv2d-36           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-37           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-38           [-1, 16, 32, 32]               0\n",
            "           Conv2d-39           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-40           [-1, 16, 32, 32]              32\n",
            "             ReLU-41           [-1, 16, 32, 32]               0\n",
            "           Conv2d-42           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-43           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-44           [-1, 16, 32, 32]               0\n",
            "           Conv2d-45           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-46           [-1, 16, 32, 32]              32\n",
            "             ReLU-47           [-1, 16, 32, 32]               0\n",
            "           Conv2d-48           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-49           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-50           [-1, 16, 32, 32]               0\n",
            "           Conv2d-51           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-52           [-1, 16, 32, 32]              32\n",
            "             ReLU-53           [-1, 16, 32, 32]               0\n",
            "           Conv2d-54           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-55           [-1, 16, 32, 32]              32\n",
            "   BasicConvBlock-56           [-1, 16, 32, 32]               0\n",
            "           Conv2d-57           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-58           [-1, 32, 16, 16]              64\n",
            "             ReLU-59           [-1, 32, 16, 16]               0\n",
            "           Conv2d-60           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-61           [-1, 32, 16, 16]              64\n",
            "      LambdaLayer-62           [-1, 32, 16, 16]               0\n",
            "   BasicConvBlock-63           [-1, 32, 16, 16]               0\n",
            "           Conv2d-64           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-65           [-1, 32, 16, 16]              64\n",
            "             ReLU-66           [-1, 32, 16, 16]               0\n",
            "           Conv2d-67           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-68           [-1, 32, 16, 16]              64\n",
            "   BasicConvBlock-69           [-1, 32, 16, 16]               0\n",
            "           Conv2d-70           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-71           [-1, 32, 16, 16]              64\n",
            "             ReLU-72           [-1, 32, 16, 16]               0\n",
            "           Conv2d-73           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-74           [-1, 32, 16, 16]              64\n",
            "   BasicConvBlock-75           [-1, 32, 16, 16]               0\n",
            "           Conv2d-76           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-77           [-1, 32, 16, 16]              64\n",
            "             ReLU-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-80           [-1, 32, 16, 16]              64\n",
            "   BasicConvBlock-81           [-1, 32, 16, 16]               0\n",
            "           Conv2d-82           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-83           [-1, 32, 16, 16]              64\n",
            "             ReLU-84           [-1, 32, 16, 16]               0\n",
            "           Conv2d-85           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-86           [-1, 32, 16, 16]              64\n",
            "   BasicConvBlock-87           [-1, 32, 16, 16]               0\n",
            "           Conv2d-88           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-89           [-1, 32, 16, 16]              64\n",
            "             ReLU-90           [-1, 32, 16, 16]               0\n",
            "           Conv2d-91           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-92           [-1, 32, 16, 16]              64\n",
            "   BasicConvBlock-93           [-1, 32, 16, 16]               0\n",
            "           Conv2d-94           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-95           [-1, 32, 16, 16]              64\n",
            "             ReLU-96           [-1, 32, 16, 16]               0\n",
            "           Conv2d-97           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-98           [-1, 32, 16, 16]              64\n",
            "   BasicConvBlock-99           [-1, 32, 16, 16]               0\n",
            "          Conv2d-100           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-101           [-1, 32, 16, 16]              64\n",
            "            ReLU-102           [-1, 32, 16, 16]               0\n",
            "          Conv2d-103           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-104           [-1, 32, 16, 16]              64\n",
            "  BasicConvBlock-105           [-1, 32, 16, 16]               0\n",
            "          Conv2d-106           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-107           [-1, 32, 16, 16]              64\n",
            "            ReLU-108           [-1, 32, 16, 16]               0\n",
            "          Conv2d-109           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-110           [-1, 32, 16, 16]              64\n",
            "  BasicConvBlock-111           [-1, 32, 16, 16]               0\n",
            "          Conv2d-112             [-1, 64, 8, 8]          18,432\n",
            "     BatchNorm2d-113             [-1, 64, 8, 8]             128\n",
            "            ReLU-114             [-1, 64, 8, 8]               0\n",
            "          Conv2d-115             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-116             [-1, 64, 8, 8]             128\n",
            "     LambdaLayer-117             [-1, 64, 8, 8]               0\n",
            "  BasicConvBlock-118             [-1, 64, 8, 8]               0\n",
            "          Conv2d-119             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-120             [-1, 64, 8, 8]             128\n",
            "            ReLU-121             [-1, 64, 8, 8]               0\n",
            "          Conv2d-122             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-123             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-124             [-1, 64, 8, 8]               0\n",
            "          Conv2d-125             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-126             [-1, 64, 8, 8]             128\n",
            "            ReLU-127             [-1, 64, 8, 8]               0\n",
            "          Conv2d-128             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-129             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-130             [-1, 64, 8, 8]               0\n",
            "          Conv2d-131             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-132             [-1, 64, 8, 8]             128\n",
            "            ReLU-133             [-1, 64, 8, 8]               0\n",
            "          Conv2d-134             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-135             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-136             [-1, 64, 8, 8]               0\n",
            "          Conv2d-137             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-138             [-1, 64, 8, 8]             128\n",
            "            ReLU-139             [-1, 64, 8, 8]               0\n",
            "          Conv2d-140             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-141             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-142             [-1, 64, 8, 8]               0\n",
            "          Conv2d-143             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-144             [-1, 64, 8, 8]             128\n",
            "            ReLU-145             [-1, 64, 8, 8]               0\n",
            "          Conv2d-146             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-147             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-148             [-1, 64, 8, 8]               0\n",
            "          Conv2d-149             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-150             [-1, 64, 8, 8]             128\n",
            "            ReLU-151             [-1, 64, 8, 8]               0\n",
            "          Conv2d-152             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-153             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-154             [-1, 64, 8, 8]               0\n",
            "          Conv2d-155             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-156             [-1, 64, 8, 8]             128\n",
            "            ReLU-157             [-1, 64, 8, 8]               0\n",
            "          Conv2d-158             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-159             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-160             [-1, 64, 8, 8]               0\n",
            "          Conv2d-161             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-162             [-1, 64, 8, 8]             128\n",
            "            ReLU-163             [-1, 64, 8, 8]               0\n",
            "          Conv2d-164             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-165             [-1, 64, 8, 8]             128\n",
            "  BasicConvBlock-166             [-1, 64, 8, 8]               0\n",
            "AdaptiveAvgPool2d-167             [-1, 64, 1, 1]               0\n",
            "          Linear-168                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 853,018\n",
            "Trainable params: 853,018\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 12.16\n",
            "Params size (MB): 3.25\n",
            "Estimated Total Size (MB): 15.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the basic building block for ResNet\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = nn.ReLU()(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet-18 architecture\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = nn.AdaptiveAvgPool2d(1)(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# Create an instance of ResNet-18\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "# Initialize the ResNet-18 model\n",
        "resnet18 = ResNet18()\n"
      ],
      "metadata": {
        "id": "vsya3ADSmxZy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18()\n",
        "model.to(device)\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PZAZzBkoiy7",
        "outputId": "80dcf392-9d61-4029-c472-68e1bb198bc7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataloader_cifar():\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split dataset into training set and validation set.\n",
        "    train_dataset, val_dataset = random_split(train_dataset, (45000, 5000))\n",
        "\n",
        "    print(\"Image shape of a random sample image : {}\".format(train_dataset[0][0].numpy().shape), end = '\\n\\n')\n",
        "\n",
        "    print(\"Training Set:   {} images\".format(len(train_dataset)))\n",
        "    print(\"Validation Set:   {} images\".format(len(val_dataset)))\n",
        "    print(\"Test Set:       {} images\".format(len(test_dataset)))\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # Generate dataloader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "A_PKurfphIBq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader = dataloader_cifar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiQT3tsGh4yJ",
        "outputId": "45b55766-89c5-4758-f2c3-11458ee530b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15857640.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Image shape of a random sample image : (3, 32, 32)\n",
            "\n",
            "Training Set:   45000 images\n",
            "Validation Set:   5000 images\n",
            "Test Set:       10000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "fVI8uQMjiRJJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    EPOCHS = 15\n",
        "    train_samples_num = 45000\n",
        "    val_samples_num = 5000\n",
        "    train_costs, val_costs = [], []\n",
        "\n",
        "    #Training phase.\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        train_running_loss = 0\n",
        "        correct_train = 0\n",
        "\n",
        "        model.train().cuda()\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Start the forward pass\n",
        "            prediction = model(inputs)\n",
        "\n",
        "            loss = criterion(prediction, labels)\n",
        "\n",
        "            # do backpropagation and update weights with step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print('outputs on which to apply torch.max ', prediction)\n",
        "            # find the maximum along the rows, use dim=1 to torch.max()\n",
        "            _, predicted_outputs = torch.max(prediction.data, 1)\n",
        "\n",
        "            # Update the running corrects\n",
        "            correct_train += (predicted_outputs == labels).float().sum().item()\n",
        "\n",
        "            train_running_loss += (loss.data.item() * inputs.shape[0])\n",
        "\n",
        "\n",
        "        train_epoch_loss = train_running_loss / train_samples_num\n",
        "\n",
        "        train_costs.append(train_epoch_loss)\n",
        "\n",
        "        train_acc =  correct_train / train_samples_num\n",
        "\n",
        "        # Now check trained weights on the validation set\n",
        "        val_running_loss = 0\n",
        "        correct_val = 0\n",
        "\n",
        "        model.eval().cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass.\n",
        "                prediction = model(inputs)\n",
        "\n",
        "                # Compute the loss.\n",
        "                loss = criterion(prediction, labels)\n",
        "\n",
        "                # Compute validation accuracy.\n",
        "                _, predicted_outputs = torch.max(prediction.data, 1)\n",
        "                correct_val += (predicted_outputs == labels).float().sum().item()\n",
        "\n",
        "            # Compute batch loss.\n",
        "            val_running_loss += (loss.data.item() * inputs.shape[0])\n",
        "\n",
        "            val_epoch_loss = val_running_loss / val_samples_num\n",
        "            val_costs.append(val_epoch_loss)\n",
        "            val_acc =  correct_val / val_samples_num\n",
        "\n",
        "        info = \"[Epoch {}/{}]: train-loss = {:0.6f} | train-acc = {:0.3f} | val-loss = {:0.6f} | val-acc = {:0.3f}\"\n",
        "\n",
        "        print(info.format(epoch+1, EPOCHS, train_epoch_loss, train_acc, val_epoch_loss, val_acc))\n",
        "\n",
        "        torch.save(model.state_dict(), '/content/checkpoint_gpu_{}'.format(epoch + 1))\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/resnet-56_weights_gpu')\n",
        "\n",
        "    return train_costs, val_costs"
      ],
      "metadata": {
        "id": "yiUY_dKDiaKB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_costs, val_costs = train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQtmXNUlinOi",
        "outputId": "4acaab48-9809-4ce6-918a-2faec640596e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/15]: train-loss = 2.497190 | train-acc = 0.101 | val-loss = 0.002810 | val-acc = 0.106\n",
            "[Epoch 2/15]: train-loss = 2.497436 | train-acc = 0.100 | val-loss = 0.003963 | val-acc = 0.105\n",
            "[Epoch 3/15]: train-loss = 2.497844 | train-acc = 0.100 | val-loss = 0.003992 | val-acc = 0.106\n",
            "[Epoch 4/15]: train-loss = 2.496700 | train-acc = 0.100 | val-loss = 0.003867 | val-acc = 0.105\n",
            "[Epoch 5/15]: train-loss = 2.496780 | train-acc = 0.100 | val-loss = 0.003594 | val-acc = 0.105\n",
            "[Epoch 6/15]: train-loss = 2.497021 | train-acc = 0.100 | val-loss = 0.004182 | val-acc = 0.105\n",
            "[Epoch 7/15]: train-loss = 2.497312 | train-acc = 0.100 | val-loss = 0.003598 | val-acc = 0.105\n",
            "[Epoch 8/15]: train-loss = 2.497635 | train-acc = 0.100 | val-loss = 0.003799 | val-acc = 0.106\n",
            "[Epoch 9/15]: train-loss = 2.497138 | train-acc = 0.100 | val-loss = 0.003741 | val-acc = 0.105\n",
            "[Epoch 10/15]: train-loss = 2.497585 | train-acc = 0.101 | val-loss = 0.003136 | val-acc = 0.106\n",
            "[Epoch 11/15]: train-loss = 2.497258 | train-acc = 0.100 | val-loss = 0.004065 | val-acc = 0.105\n",
            "[Epoch 12/15]: train-loss = 2.497205 | train-acc = 0.100 | val-loss = 0.003952 | val-acc = 0.106\n",
            "[Epoch 13/15]: train-loss = 2.497112 | train-acc = 0.101 | val-loss = 0.004036 | val-acc = 0.106\n",
            "[Epoch 14/15]: train-loss = 2.496756 | train-acc = 0.100 | val-loss = 0.003642 | val-acc = 0.105\n",
            "[Epoch 15/15]: train-loss = 2.497354 | train-acc = 0.100 | val-loss = 0.003970 | val-acc = 0.106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet56()\n",
        "model.load_state_dict(torch.load('/content/resnet-56_weights_gpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7oI1zZDirK0",
        "outputId": "5f1081cd-9dcc-4bfb-9e21-0b64b6236313"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples_num = 10000\n",
        "correct = 0\n",
        "\n",
        "model.eval().cuda()\n",
        "\n",
        "with  torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Make predictions.\n",
        "        prediction = model(inputs)\n",
        "\n",
        "        # Retrieve predictions indexes.\n",
        "        _, predicted_class = torch.max(prediction.data, 1)\n",
        "\n",
        "        # Compute number of correct predictions.\n",
        "        correct += (predicted_class == labels).float().sum().item()\n",
        "\n",
        "test_accuracy = correct / test_samples_num\n",
        "print('Test accuracy: {}'.format(test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f8pAsWrmuNy",
        "outputId": "ad3d08d6-34e6-4211-c57b-dcea37ab3d6e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.1087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKxlDxsuouYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}